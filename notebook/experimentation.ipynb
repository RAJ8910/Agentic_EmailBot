{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings \n",
    "# Changed: Import Chroma instead of FAISS\n",
    "from langchain_chroma import Chroma \n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a65b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load environment variables (for API key)\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not groq_api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY not found in environment variables. Please set it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c53b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\" \n",
    "\n",
    "# Changed: Define the directory path where your PDFs are located\n",
    "PDF_DIRECTORY = \"../docs\" \n",
    "\n",
    "CHROMA_DB_PATH = \"chroma_index_hf_directory\" # Changed index path for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f3af627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Initialize LLM from Groq ---\n",
    "llm = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model_name=MODEL_NAME,\n",
    "    temperature=0.7 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0c87df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from directory: ../docs...\n",
      "Loaded 31 raw documents (pages).\n",
      "Splitting documents into chunks...\n",
      "Created 61 chunks from all documents.\n",
      "Generating embeddings using sentence-transformers/all-MiniLM-L6-v2 and creating ChromaDB vector store...\n",
      "ChromaDB vector store created and persisted.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Document Loading and Processing (Indexing Phase) ---\n",
    "\n",
    "# Check if ChromaDB data already exists to avoid re-processing\n",
    "# ChromaDB handles persistence by checking the persist_directory\n",
    "if os.path.exists(CHROMA_DB_PATH) and os.listdir(CHROMA_DB_PATH):\n",
    "    print(f\"Loading existing ChromaDB from {CHROMA_DB_PATH}...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "    # Changed: Initialize Chroma with persist_directory\n",
    "    vector_store = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)\n",
    "    print(\"ChromaDB loaded.\")\n",
    "else:\n",
    "    print(f\"Loading documents from directory: {PDF_DIRECTORY}...\")\n",
    "    \n",
    "    if not os.path.exists(PDF_DIRECTORY):\n",
    "        raise FileNotFoundError(f\"The specified PDF directory does not exist: {PDF_DIRECTORY}\")\n",
    "\n",
    "    loader = PyPDFDirectoryLoader(path=PDF_DIRECTORY, glob=\"**/*.pdf\", recursive=True)\n",
    "    documents = loader.load()\n",
    "\n",
    "    if not documents:\n",
    "        print(f\"No PDF documents found in {PDF_DIRECTORY}. Please check the path and content.\")\n",
    "        exit() \n",
    "\n",
    "    print(f\"Loaded {len(documents)} raw documents (pages).\")\n",
    "    \n",
    "    print(f\"Splitting documents into chunks...\")\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(chunks)} chunks from all documents.\")\n",
    "\n",
    "    print(f\"Generating embeddings using {EMBEDDING_MODEL_NAME} and creating ChromaDB vector store...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME, model_kwargs={'device': 'cpu'}) \n",
    "\n",
    "    # Changed: Create ChromaDB from documents, specifying the persist_directory\n",
    "    vector_store = Chroma.from_documents(\n",
    "        chunks, \n",
    "        embeddings, \n",
    "        persist_directory=CHROMA_DB_PATH\n",
    "    )\n",
    "    print(\"ChromaDB vector store created and persisted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f043749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Setup Retrieval Chain (Querying Phase) ---\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context.\n",
    "If you don't know the answer, just say \"I don't know\" and do not try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66969c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAG System Ready ---\n",
      "\n",
      "--- Processing Question 1/1 ---\n",
      "Question: Can you tell me about the company overview of evergreen assurance ltd??\n",
      "\n",
      "Searching for relevant information...\n",
      "\n",
      "--- Answer ---\n",
      "<think>\n",
      "Okay, I need to answer the question about the company overview of Evergreen Assurance Ltd. using the provided context. Let me read through the context carefully.\n",
      "\n",
      "The context starts with a disclaimer stating it's a summary of products and general terms, so it's illustrative and not the official policy. Then it goes into the company overview.\n",
      "\n",
      "From the context, Evergreen Assurance Ltd. is described as a premier insurance provider in India. Their mission is to secure customers' financial futures with transparent, innovative, and customer-centric products. They aim to be a steadfast partner to policyholders, offering peace of mind and robust protection against life's uncertainties. The document outlines their product portfolio and terms, serving as a comprehensive knowledge base.\n",
      "\n",
      "I should structure the answer to include all these points clearly. Make sure to mention their commitment to transparency, innovation, and customer focus, as well as their role as a trusted partner providing financial security.\n",
      "</think>\n",
      "\n",
      "**Company Overview of Evergreen Assurance Ltd.**\n",
      "\n",
      "Evergreen Assurance Ltd. is a leading insurance provider in India, dedicated to safeguarding the financial future of its customers. The company offers a range of transparent, innovative, and customer-centric products designed to provide peace of mind and robust protection against life's uncertainties. Committed to being a steadfast partner to its policyholders, Evergreen Assurance Ltd. ensures a comprehensive approach to financial security through its diverse product portfolio and clear terms.\n",
      "\n",
      "--- Sources (if available) ---\n",
      "- Source: ..\\docs\\General.pdf, Page: 0\n",
      "- Source: ..\\docs\\General.pdf, Page: 8\n",
      "- Source: ..\\docs\\InsuranceNotes.pdf, Page: 1\n",
      "------------------------------\n",
      "\n",
      "--- All static questions processed. Exiting. ---\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Ask Questions (Static List) ---\n",
    "print(\"\\n--- RAG System Ready ---\")\n",
    "\n",
    "# Define your static list of questions\n",
    "static_questions = [\n",
    "    \"Can you tell me about the company overview of evergreen assurance ltd?\",\n",
    "]\n",
    "\n",
    "for i, question in enumerate(static_questions):\n",
    "    print(f\"\\n--- Processing Question {i+1}/{len(static_questions)} ---\")\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    print(\"\\nSearching for relevant information...\")\n",
    "    response = retrieval_chain.invoke({\"input\": question})\n",
    "\n",
    "    print(\"\\n--- Answer ---\")\n",
    "    print(response[\"answer\"])\n",
    "    print(\"\\n--- Sources (if available) ---\")\n",
    "    if \"context\" in response:\n",
    "        sorted_context = sorted(response[\"context\"], key=lambda doc: (doc.metadata.get('source', ''), doc.metadata.get('page', 0)))\n",
    "        seen_sources = set()\n",
    "        for doc in sorted_context:\n",
    "            source_info = f\"Source: {doc.metadata.get('source', 'N/A')}\"\n",
    "            page_info = f\"Page: {doc.metadata.get('page', 'N/A')}\"\n",
    "            \n",
    "            if (source_info, page_info) not in seen_sources:\n",
    "                print(f\"- {source_info}, {page_info}\")\n",
    "                seen_sources.add((source_info, page_info))\n",
    "    else:\n",
    "        print(\"No specific sources found in context.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "print(\"\\n--- All static questions processed. Exiting. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c9405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_EmailBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
